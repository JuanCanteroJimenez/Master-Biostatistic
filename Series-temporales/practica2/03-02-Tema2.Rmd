---
title: "Series Temporales: Alisado Exponencial"
subtitle: "Máster de Bioestadística (Modelización Estadística)"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
output: 
  html_document:
    theme: cerulean
    highlight: pygments 
    fig_caption: false
    df_print: kable
    toc: true
    toc_depth: 2
    toc_float: 
      collapsed: true
    number_sections: true
    self_contained: true
    code_download: true
---

```{r chunk_setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```

```{r options_setup, echo = FALSE}
options(scipen = 999) #- para quitar la notacion cientifica
```

```{r librerias, echo = FALSE}
library(forecast)
library(ggplot2); theme_set(theme_bw())
library(gridExtra)
library(grid)
```

# Introducción

En muchos casos es preciso aplicar un método de predicción rápido y sencillo:

* A causa del elevado número de series que tienen que ser analizadas.
* Debido a la rapidez con que las predicciones se han de dar.
      
Actualmente existen muchos métodos sencillos de predicción, entre lo que cabe destacar dos:

* __Métodos de media móvil__ (no los veremos en este curso pero puedes aprender sobre ellos [aqui](http://uc-r.github.io/ts_moving_averages) y [aqui](https://cran.r-project.org/web/packages/smooth/vignettes/sma.html)).
* __Métodos de alisado exponencial__.
    
Estas técnicas, a pesar de su sencillez, son bastante adecuadas cuando la previsión es a corto plazo:

>"Statistically sophisticated or complex methods do not necessarily produce more accurate forecasts than simpler ones." Makridakis y Hibon (2000).
      
Veremos en detalle los métodos de alisado exponencial por ser muy versátiles, pudiéndose aplicar a cualquier serie, independientemente de sus componentes, y haber demostrado una gran capacidad de ajuste y calidad de predicción. En ellos se hace uso de datos pasados para obtener una nueva serie más _suave_ o alisada, a partir de la cual se realizarán las predicciones. Existe un amplio menú de métodos de alisado alternativos y la elección del más adecuado dependerá de las componentes que presenta la serie y del tipo de esquema.

\
\

# Criterios de calidad

En este tema y en los siguientes se verán diferentes métodos para predecir una serie temporal. Así, es preciso definir criterios de bondad de ajuste que permitan estimar tanto la calidad del ajuste como de las predicciones de un método.

> "The rankings of the performance of the various methods vary according to the accuracy measure being used."  Makridakis y Hibon (2000).
     
\

## Notación y definiciones


 
Dada una serie temporal $\{y_t\}_{t=1}^T$, se define:

* __Previsión $h$ periodos adelante__, como la previsión de la serie para el periodo $t+h$ disponiendo de información hasta el periodo $t$, y se denota por $\hat{y}_{t+h|t}$. Por simplicidad lo escribiremos también como $\hat{y}_{t+h}$.

\vspace{0.3cm}

* Así, $\hat{y}_{t+1|t}$ es la __previsión un periodo adelante__ o a un periodo vista. Es decir, la previsión de la serie en $t+1$ desde el periodo $t$.

\vspace{0.3cm}

* De nuevo, por simplicidad denotaremos a $\hat{y}_{t+1|t}$ como $\hat{y}_{t+1}$; y como $\hat{y}_{t}$ a la previsión en $t$, con datos hasta el periodo $t-1$ ($\hat{y}_{t} = \hat{y}_{t|t-1}$).

Se define como __error de previsión__ a un periodo vista a 
$$\hat{e}_t=y_t-\hat{y}_t,$$
de forma que la serie $\{\hat{e}_t\}_{t=1}^T$ nos permitirá definir varios criterios de calidad de ajuste. 
  
\

## Medidas de precisión de la predicción
 
Dada una serie $\{y_t\}_{t=1}^T$, un método de predicción y su vector de errores asociado $\{\hat{e}_t\}_{t=1}^T$, podemos definir múltiples medidas de calidad del método de predicción que hacen referencia a la presencia de sesgo en las predicciones, la magnitud del error cometido y la calidad del intervalo de confianza de las predicciones. Las más habituales son (siglas en inglés):

* Error medio (ME): $\frac{1}{T}\sum_{t=1}^T \hat{e}_t$

\vspace{0.3cm}

* __Raíz del error cuadrático medio (RMSE)__: $\sqrt{\frac{1}{T}\sum_{t=1}^T \hat{e}^2_t}$

\vspace{0.3cm}

* Error absoluto medio (MAE): $\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|$

\vspace{0.3cm}

* Error porcentual medio (MPE): $\frac{100}{T}\sum_{t=1}^T \frac{\hat{e}_t}{y_t}$

\vspace{0.3cm}

* __Error porcentual absoluto medio (MAPE)__: $\frac{100}{T}\sum_{t=1}^T \big|\frac{\hat{e}_t}{y_t}\big|$

\vspace{0.3cm}

* Error porcentual absoluto medio simétrico (sMAPE): $\frac{200}{T}\sum_{t=1}^T \Big|\frac{\hat{e}_t}{y_t + \hat{y}_t}\Big|$

\vspace{0.3cm}

* Error escalado absoluto medio (MASE): $\big(\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|\big)/q$, donde $q$ es el error absoluto medio para un método ingenuo de predicción:
  * $q=\frac{1}{T-1}\sum_{t=2}^T |y_t-y_{t-1}|$ para series _sin_ estacionalidad
  * $q=\frac{1}{T-m}\sum_{t=m+1}^T |y_t-y_{t-m}|$ para series _con_ estacionalidad

\vspace{0.3cm}

* Correlación entre $\hat{e}_t$ y $\hat{e}_{t-1}$ (ACF1).

\

ME y MPE permiten valorar el sesgo de las predicciones (que estas estén sistemáticamente por encima o por debajo de los valores reales).

* Lo esperado es un valor cercano a cero (con relación al valor medio de la serie). Valores muy alejados de cero son indicadores de sesgo de predicción.

RMSE y MAE indican el error medio cometido, medido en las mismas unidades que la serie temporal.

* Están acotadas inferiormente por el valor óptimo de 0, pero no hay cota superior.

MAPE y sMAPE indican el error porcentual medio cometido.

* Están acotadas inferiormente por el valor óptimo de 0%, y la cota superior natural es 100%, aunque podría sobrepasarse.
* Si $y_t$ puede valer 0, entonces MAPE no se puede calcular. Además, MAPE penaliza más los errores negativos frente a los errores positivos. La medida de precisión sMAPE se define a fin de corregir estos problemas.
      
MASE es la ratio entre el error del método usado y el error de un método ingenuo de predicción. Permite saber cuánto ganamos en capacidad predictiva al pasar de un método ingenuo a otro más complicado.

* Un valor cercano a 1 indica que el método usado no es mejor que el método ingenuo
* Cuanto más cercano a 0, mejor es el método usado respecto del método ingenuo
* Su complementario a 1 se puede interpretar como la tasa de mejora

ACF1 evalúa la capacidad de mejora que hay en la estimación del intervalo de confianza de las predicciones. Lo veremos con más detalle en el tema de modelos ARIMA. Por ahora basta saber que:

* Un valor muy cercano a 0 indica que hay poca capacidad de mejora.
* Un valor cercano a 1 o -1 indica que hay mucha capacidad de mejora.

Las _medias_ se pueden sustituir por _medianas_. Esto es especialmente útil cuando para algunas observaciones hay errores atípicamente altos.

\

Si para realizar la predicción del periodo $t$ se usa una metodología que utiliza datos hasta dicho periodo, se hablará de **predicción y error intra-muestral**. En caso contrario, la predicción del periodo $t$ usa una metodología que solo necesita de datos hasta el periodo $t-1$, se hablará de **predicción y error extra-muestral**.

Si los indicadores de calidad se basan en predicciones intra-muestrales a un periodo vista, presentan dos problemas. Primero, evalúan el error de predicción a un periodo vista, cuando en muchas situaciones reales las predicciones se realizan sobre un horizonte temporal más amplio. Segundo, son errores intra-muestrales, resultantes de predecir los mismos datos que ha usado el método para calcular la predicción y, por tanto, sobre-estiman la capacidad predictiva del modelo.

Veremos en este tema métodos de evaluación de la calidad de las predicciones que superan estas limitaciones.

\
\

# Métodos sencillos de predicción

Algunos métodos de predicción son extremadamente sencillos y sorprendentemente eficaces, son los denominados métodos ingenuos. Estos métodos:

* posibilitan realizar predicciones prácticamente sin realizar ningún cálculo. 
* como son muy sencillos, dan las previsiones con mayor error (menos precisas). El error de un método ingenuo sirve de punto de referencia (_benchmark_) para valorar la necesidad de aplicar otros métodos más complicados con el objetivo de mejorar la calidad de las predicciones. 

Veamos algunos métodos ingenuos y sus funciones en el paquete `forecast`.

\

## Métodos sencillos de predicción

### Series _sin_ tendencia y _sin_ estacionalidad {-}

**Método de la Media**: $\hat{y}_{T+h}=(y_1+\ldots,y_T)/T$.

* La predicción para cualquier periodo futuro es la __media__ de las observaciones disponibles previas.
* Función de `R`: `meanf(y, h)`
    
**Método ingenuo I**: $\hat{y}_{T+h}=y_T$.

* La predicción para cualquier periodo futuro es la __última__ observación disponible.
* Función de `R`: `naive(y, h)` o `rwf(y, h)` (_rw_ de random walk)


### Series _con_ tendencia y _sin_ estacionalidad {-}

**Método ingenuo II**: $\hat{y}_{T+h}=y_T + h(y_T-y_{T-1})$.

* La predicción $h$ periodos adelante es la __última observación__ disponible más $h$ veces el __último incremento__ observado. 
* No tiene función en `R`, pero se podría emular mediante la función `holt` (véase epígrafe de 4.5 Alisado exponencial de Holt).
      
**Método de la deriva**: $\hat{y}_{T+h}=y_T+h\frac{y_T - y_1}{T-1}$.

* La predicción $h$ periodos adelante es la __última observación__ disponible más $h$ veces el __incremento medio__ observado.
* Función de `R`: `rwf(y, h, drift = TRUE)`  


### Series _sin_ tendencia y _con_ estacionalidad {-}

**Método ingenuo con estacionalidad**: $\hat{y}_{T+h}=y_{T-m(k+1)}$.

* $k$ es la parte entera de $(h-1)/m$, es decir, el número de años completos en el periodo de predicción previo al periodo $T+h$.
* La predicción para un periodo es la __última observación disponible de la misma estación que la fecha que se desea predecir__.
* Función de `R`: `snaive(y, h)`
    
__No hay métodos ingenuos cuando la serie tiene tendencia y estacionalidad__, aunque la aplicación del método ingenuo con estacionalidad suele ser muy efectiva.

\

## Ejemplo de aplicación

### Serie Libros {-}
 
```{r}
libros <- read.csv2("./series/libros.csv", header = TRUE)
libros <- ts(libros[ ,2], start = 1993, frequency  = 1)
```

En la figura 1 se muestra el resultado gráfico de la aplicación de algunos de estos métodos sencillos a la serie Libros (número de títulos publicados anualmente en España desde 1993 hasta 2018), con independencia de su adecuación dadas las componentes de esta serie. Se ha fijado un horizonte de previsión de cinco años (`h = 5`). El argumento `PI = FALSE` hace que no se impriman los intervalos de confianza de las predicciones.

Los métodos de la Media e Ingenuo I realizan una predicción constante, el primero la media de títulos en el periodo de análisis (`r as.integer(mean(libros))`) y el segundo el último dato observado (`r tail(as.integer(libros), n=1)`). El método de deriva ofrece una predicción creciente porque la serie Libros tiene una pendiente media positiva en el periodo de análisis.

Recuerda que debes cargar las librerías `forecast` y `ggplot2`.

```{r}
(mediaLibros <- meanf(libros, h = 5))
(naiveLibros <- naive(libros, h = 5))
(derivaLibros <- rwf(libros,  h = 5, drift = TRUE))
 

autoplot(libros, series = "Libros",
                xlab = "",
                ylab = "Títulos",
                main = "Figura 1. Libros y predicción por métodos sencillos") +
  autolayer(mediaLibros, series="Media", PI = FALSE) +
  autolayer(naiveLibros, series="Ingenuo", PI = FALSE) +
  autolayer(derivaLibros, series="Deriva", PI = FALSE) +
  scale_colour_discrete(limits=c("Libros", "Media", "Ingenuo", "Deriva")) +
  guides(colour = guide_legend(title = "Métodos")) + 
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1))
```

Con la función `accuracy` se puede obtener el error de predicción intra-muestral a un periodo vista de cada método:

```{r, eval = FALSE}
accuracy(mediaLibros)
accuracy(naiveLibros)
accuracy(derivaLibros)
```

```{r, echo=FALSE}
tmp <- rbind(
  accuracy(mediaLibros),
  accuracy(naiveLibros),
  accuracy(derivaLibros)
)
tmp <- round(tmp,2)
rownames(tmp) <- c("Media","Ingenuo I","Deriva")
tmp
```

Podemos destacar que:

* El método de _Media_ presenta una baja calidad de ajuste debido a que la serie Libros tiene tendencia (MAPE =  14%). Además, el intervalo de confianza de las predicciones no es fiable (ACF1 = 0.77).
* El método de _Deriva_ tiene la mejor calidad de ajuste, con un error porcentual del 6.9% (MAPE), y un error medio aproximado de 6,000 títulos (RMSE). No presenta sesgo (ME = 0) y el intervalo de confianza de las predicciones es fiable (ACF1 = -0.04).
* El método _Ingenuo I_ tiene buena calidad de ajuste, pero las previsiones están algo sesgadas (ME = 857).
* Para series sin estacionalidad el método sencillo de comparación usado en el cálculo del MASE es el _Ingenuo I_. Es por ello que este indicador vale 1 para este método.
* El error medio (ME) siempre será nulo para el método de la _Media_ y de la _Deriva_, lo que indica que nos equivocamos tanto por exceso como por defecto. Esta es una buena propiedad, que el método _Ingenuo I_ no verifica.

### Serie Nacimientos {-}

Podemos usar el método ingenuo con estacionalidad con la serie Nacimientos para obtener una previsión a dos años vista. El error absoluto porcentual medio es del 3.6%. Es decir, aplicando algo tan simple como predecir el número de nacimientos para un mes como los nacimientos del mismo mes del año previo, tenemos ya un error de predicción muy bajo. La figura 2 muestra la serie y la predicción que, debido al método usado, no incorpora la tendencia decreciente de los últimos años.

```{r}
nacimientos <- read.csv2("./series/nacimientos.csv", header = TRUE)
nacimientos <- ts(nacimientos[, 2],
                  start = c(1975, 1),
                  frequency = 12)

(snaive.nacimientos <- snaive(nacimientos, h = 24, level = 95))
accuracy(snaive.nacimientos)

autoplot(snaive.nacimientos,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 2. Nacimientos y predicción por el método Ingenuo con estacionalidad")
```


\
\

# Evaluación de las predicciones

Las medidas que hemos usado hasta ahora para valorar la calidad de las predicciones son realmente medidas de bondad de ajuste, es decir, medidas de la calidad de __previsiones intra-muestrales a un periodo vista__. Valoran en que medida los datos se ajustan a un patrón o modelo, pero no evalúan la calidad de la previsiones ante nuevos datos.

En este epígrafe vamos a ver dos metodologías que podemos usar para valorar la calidad de las __previsiones extra-muestrales__, que es realmente lo que nos interesa. Estas dos metodologías están relacionadas con los métodos de _Training set/Test set_ y _Cross-validation_ usuales en el análisis de las predicciones con datos transversales, pero adaptadas a datos temporales.

## Validación por la metodología de _Training set/Test set_ para Series Temporales

Vamos a mejorar la estimación de la calidad de las predicciones obteniendo las medidas de error para __previsiones extra-muestrales a varios periodos vista__ usando la filosofía del método _training set/test set_. Dividimos la serie temporal $\{y_t\}_{t=1}^T$ en dos subseries, los primeros datos $\{y_t\}_{t=1}^{T_0}$, $T_0 < T$ se usarán para estimar el modelo, y los últimos datos $\{y_t\}_{t={T_0+1}}^{T}$ para validar el modelo.

Esta metodología, muy efectiva para datos de corte transversal, genera dos problemas cuando se aplica a series temporales: _i_) el error obtenido es una mezcla de errores de predicción a corto, medio y largo plazo difícil de valorar; _ii_) los resultados dependen tremendamente del punto de corte temporal seleccionado.

### Serie Libros {-}

Vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie. 

```{r, eval = FALSE}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos y
# predecimos los 6 años que hemos quitado de la serie 
librosExtraPre <- rwf(librosIntra,  h = 6, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
accuracy(librosExtraPre, librosExtra)
```

```{r, echo = FALSE}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos y
# predecimos los 7 años que hemos quitado de la serie 
librosExtraPre <- rwf(librosIntra,  h = 6, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
round(accuracy(librosExtraPre, librosExtra), 2)

error.muestral.1 <- round(accuracy(librosExtraPre, librosExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(librosExtraPre, librosExtra)[2,5],1)
```

Atendiendo al MAPE se tiene que el error de __previsión a un periodo vista__ en el __periodo intra-muestral__ de __1993 a 2012__ es del `r error.muestral.1`%; mientras que el error de __previsión a largo plazo__ en el __periodo extra-muestral__ de __2013 a 2018__ es del `r error.extramuestral.n`%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas (sobre-estiman la realidad). En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas. 

Un gráfico puede ayudar a entender este proceso de validación. En la figura 3:

* La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.
* La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.
* La previsión _intra_-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.
* La línea en rojo es la previsión _extra_-muestral a largo plazo. Observa que todas las previsiones están por encima del valor real de la serie.
* Al lado de cada previsión (intra- y extra-muestral) se ha indicado el error estimado (MAPE).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r,echo=FALSE}
autoplot(libros, series = "Libros",
         main="Figura 3. Libros, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Títulos"
         ) +
  autolayer(fitted(librosExtraPre), series = "Libros (ajustada)") + 
  autolayer(librosExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2012.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Libros"="black",
                               "Libros (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=1999, y=65000, label="6.5%", colour = "blue") +
  annotate("text", x=2016, y=72000, label="26.7%", colour = "red") +
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1)) 
```

### Serie Nacimientos {-}

Calculamos de nuevo los diferentes criterios de bondad de ajuste para valorar la calidad de las previsiones extra-muestrales a largo plazo. En este caso vamos a reservar los últimos 36 meses como periodo extra-muestral.
  
```{r, eval = FALSE}
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

accuracy(nacimientosExtraPre, nacimientosExtra)
```

```{r, echo = FALSE}
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

round(accuracy(nacimientosExtraPre, nacimientosExtra), 2)
```

```{r, echo = FALSE}
autoplot(nacimientos, series = "Nacimientos",
         main="Figura 4. Nacimientos, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Nacimientos"
         ) +
  autolayer(fitted(nacimientosExtraPre), series = "Nacimientos (ajustada)") + 
  autolayer(nacimientosExtraPre$mean, series = "Predicción") + 
  scale_colour_manual(values=c("Nacimientos"="black",
                               "Nacimientos (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=2012, y=45000, label="3.6%", colour = "blue") +
  annotate("text", x=2018, y=40000, label="7.7%", colour = "red") + 
  theme(legend.position=c(0.98,0.98), legend.justification=c(1,1)) 
```

Las previsiones extra-muestrales muestran una menor pendiente que los casos reales de nacimientos. Así, conforme se avanza en el horizonte temporal las previsiones se van alejando de la realidad y el error extra-muestral es del 7.7%, reducido pero que duplica el error de estimación intra-muestral (3.6%).

\

## Validación cruzada para Series Temporales

Hemos visto dos alternativas para evaluar la calidad de un método de predicción de series temporales, uno basado en predicciones intra-muestrales a un periodo vista y otro basado en predicciones extra-muestrales a largo plazo, ambas con sus inconvenientes.

Veamos ahora una técnica, basada en el concepto de validación cruzada (_cross validation_) que permite obtener de forma individualizada los errores de previsión extra-muestral a un periodo vista, a dos periodos vista, etc.

Supongamos que para estimar el modelo se necesita un mínimo de $k$ observaciones y que se desea predecir hasta un horizonte temporal $h$.

* Seleccionamos las observaciones $1,2,...,k$ para estimar el modelo y predecimos las observaciones desde $k+1$ hasta $k+h$. Tenemos, por tanto, $h$ predicciones.
* Calculamos el error de predicción para las predicciones desde $k+1$ hasta $k+h$.
* Repetimos este proceso desplazando el número de observaciones seleccionadas para la estimación un periodo adelante. Es decir, ahora usamos las observaciones $2,3,...,k+1$ para estimar el modelo, predecimos las observaciones desde $k+2$ hasta $k+1+h$ y calculamos el error de predicción.
* Iteramos el proceso, desplazando cada vez las observaciones de la estimación un periodo adelante.
* En general para $i=0,1,...,T-k-h$, donde $T$ es el número total de observaciones:
  
  1. Seleccionamos las observaciones $i+1,i+2,...,i+k$ para estimar el modelo.
  2. Predecimos las observaciones desde $i+k+1$ hasta $i+k+h$.
  3. Calculamos el error de predicción para las observaciones desde $i+k+1$ hasta $i+k+h$.
  4. Para cada horizonte temporal de predicción se calcula la medida de error deseada.

\
\

![](./imagenes/RollingWindows.png)

Este procedimiento se denomina __origen de predicción móvil__ (_rolling forecast origin_) o _rolling windows_.

Cuando se aplica esta metodología hay que tener en cuenta que los resultados pueden depender del número $k$ de datos usados para la estimación del modelo.

### Ejemplo de aplicación con Nacimientos {-}

Vamos a aplicar la metodología previa a la serie anual de Nacimientos. Asumimos que se precisan veinte años para hacer una buena estimación, $k=20$, y que el horizonte temporal es de cinco años, $h = 5$ meses. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde uno a cinco años.
  
```{r}  
nacAnual <- aggregate(nacimientos, FUN = sum)
k <- 20                   #Minimo numero de datos para estimar
h <- 5                    #Horizonte de las prediciciones
TT <- length(nacAnual)    #Longitud serie
s <- TT - k - h           #Total de estimaciones

mapeRwf <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacAnual, start = i + 1, end = i + k)
  test.set <-  subset(nacAnual, start = i + k + 1, end = i + k + h)
  
  fcast <- rwf(train.set, h = h, drift = TRUE)
  mapeRwf[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

mapeRwf <- colMeans(mapeRwf)
round(mapeRwf, 2)
```

El error de previsión extra-muestral crece linealmente con el horizonte de previsión. Para el primer año el error de predicción se mantiene en un moderado 4.2%. Sin embargo, para el segundo año de predicción el MAPE salta al 8.2% y para los restantes años sigue creciendo rápidamente. Predecir usando la tendencia media solo es un buen método para predecir a un año vista.

\
\

# Métodos de Alisado Exponencial

## Introducción

Los métodos de alisado exponencial aparecen en los años 50 de la mano de Brown, Holt y Winters y han sido la raíz de uno de los métodos de predicción más sencillos y eficaces. La idea básica es predecir usando una media ponderada de los datos pasados, donde los más recientes tienen un peso mayor y este decae exponencialmente conforme usamos observaciones más antiguas.

El alisado exponencial es una familia de métodos de ajuste y previsión que ofrece muy buenos resultados para predicciones a corto plazo o para predecir series con pocos datos o _sencillas_ (sin mucho _ruido_).

Suponen un grado de modelización mayor que los métodos sencillos vistos previamente, pero sin alcanzar la complejidad de otras metodologías (modelos ARIMA).  

En origen, son métodos descriptivos con el único objetivo de producir __predicciones puntuales__. Sin embargo, su enfoque como modelos de _espacio de estados_ posibilita un marco teórico para obtener __intervalos de predicción__.

\

## Componentes de una serie en el contexto del alisado exponencial

Para obtener una predicción en el periodo $t+1$ con datos hasta el periodo $t$ necesitamos tres componentes:

* La estimación del nivel de la serie en el periodo $t$: $l_t$
* La estimación de la pendiente de la serie en el periodo $t$: $b_t$
* La estimación de la estacionalidad en el mes correspondiente al periodo $t+1$ con datos hasta $t$: $s_{t + 1 - m}$ (recuerda, $m$ es el orden estacional

A partir de estas componentes, obtenidas en el periodo $t$ y para un esquema aditivo, se tendría que la predicción en el periodo $t+1$ es:
$$\widehat{y}_{t+1} = l_t+b_t+s_{t+1-m}.$$
En general, las componentes pueden __existir o no__ y se pueden combinar entre ellas __aditiva o multiplicativamente__. Veamos algunos casos:

* Existen todas y son multiplicativas:
$$\widehat{y}_{t+1}=l_t \cdot b_t \cdot s_{t + 1 - m}$$
* Existen todas, nivel y pendiente aditivas, y estacionalidad multiplicativa:
$$\widehat{y}_{t+1}=(l_t+b_t)s_{t + 1 - m}$$
* No hay pendiente y la estacionalidad es aditiva:
$$\widehat{y}_{t+1}=l_t+s_{t + 1 - m}$$

¿Como obtenemos los valores de $l_t$, $b_t$ y $s_{t + 1 - m}$? Mediante __expresiones recursivas__, donde cada componente se calcula a partir de los valores hasta $t$ de la serie y de las componentes:
$$
\begin{aligned}
l_t& = f_l(y_t,y_{t-1}\ldots, l_{t-1},l_{t-2}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
b_t& = f_b(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
s_t& = f_s(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t},b_{t-1}\ldots,s_{t-1},s_{t-2}\ldots)
\end{aligned}
$$
Por ejemplo, el _método ingenuo I_ se puede interpretar dentro de este contexto como un método de alisado donde $l_t = y_t$ y no hay ni pendiente ni estacionalidad. Por tanto, $\widehat{y}_{T+1} = l_{T} = y_{T}$.

De la misma forma, el _método ingenuo II_ se puede interpretar como un método de alisado donde $l_t = y_t$, $b_t = y_t - y_{t-1}$ y no hay estacionalidad. Entonces, $\widehat{y}_{T+1}=l_T + b_T = y_T + (y_T - y_{T-1})$.
    
En las expresiones previas hemos supuesto que se quería obtener una predicción a un periodo vista ($\widehat{y}_{t+1}$). Si el objetivo es estimar una previsión $h$ periodos hacia delante desde el periodo $t$, $\widehat{y}_{t+h}$, hay que realizar algunas modificaciones. Por ejemplo, para el caso aditivo se tendría que 
$$\widehat{y}_{t+h} = l_t+hb_t+s_{t+h-m(k+1)}$$
donde $k = \lfloor (h-1)/m\rfloor$.

El concepto de componentes aquí visto no coincide con el definido en el Tema 1. Sin embargo, podemos asimilar la tendencia de una serie como la suma (multiplicación) del nivel y la pendiente $T_{t+1} = l_t + b_t$ ($T_{t+1} = l_t \cdot b_t$) y de esta forma ambas definiciones de componentes de una serie se hacen compatibles.

\
\

## Casos posibles

Todas las series tiene nivel, pero dependiendo del tipo de pendiente y estacionalidad hay 15 casos posibles, mostrados en la tabla siguiente.

|    Tendencia          |           | Estacionalidad |                  |
|:----------------------|:---------:|:--------------:|:----------------:|
|                       | Ninguna (N) | Aditiva (A) | Multiplicativa (M)        |
| Ninguna (N)           |__N, N__   |       N, A     |        N, M      |
| Aditiva (A)           |__A, N__   |   __A, A__     |    __A, M__      |
| Aditiva Amortiguada (Ad)  |__Ad, N__  |      Ad, A     |       Ad, M      |
| Multiplicativa (M)    |    M, N   |       M, A     |        M, M      |
| Multiplicativa Amortiguada (Md) |    Md, N  |      Md, A     |       Md, M      |


Cada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización.

Si se añade que el error puede ser aditivo o multiplicativo, da 30 posibilidades. **El tipo de error (aditivo o multiplicativo) no afecta ni a la estimación ni a la previsión puntual, sólo es relevante en el cálculo del intervalo de confianza de las predicciones.**

Los modelos más usuales son:

* (N, N):   Alisado exponencial simple
* (A, N):   Alisado de Holt
* (Ad, N):  Alisado con tendencia amortiguada (d de _damped_)
* (A, A):   Alisado de Holt-Winters aditivo
* (A, M):   Alisado de Holt-Winters multiplicativo

Acude al artículo de [Rob J. Hyndman y Yeasmin Khandakar (2008)](http://www.jstatsoft.org/v27/i03/paper) para saber más de cada modelo, o al libro _Forecasting with Exponential Smoothing: the State Space Approach_ (2008) de Hyndman y otros autores.

\

## Alisado exponencial simple (N, N)

### Definición {-}

El alisado exponencial simple es adecuado para una serie estacionaria y sin estacionalidad. Es decir, una serie que se mueve alrededor de un nivel constante.

La ecuación de la __predicción intra-muestral__ es 
$$\hat{y}_{t+1} = \alpha y_t + \alpha (1-\alpha) y_{t-1} + \alpha (1-\alpha)^2 y_{t-2} + \alpha (1-\alpha)^3 y_{t-3} + \ldots =  \alpha y_t + (1-\alpha)\hat{y}_{t},$$
donde $0 \leq \alpha \leq 1$ es el parámetro de suavizado. La primera __predicción extra-muestral__ queda 
$$\hat{y}_{T+1}=\alpha y_T + (1-\alpha)\hat{y}_{T}$$
y para las restantes
$$\hat{y}_{T+h} = \hat{y}_{T+1}.$$

### Formulas interactivas de sus componentes {-}

En el alisado exponencial simple solo hay una componente, el nivel $l_t$.

* La __ecuación recursiva__ de suavizado es $l_t=\alpha y_t + (1-\alpha)l_{t-1}$
* La ecuación de __predicción intra-muestral__ es $\hat{y}_{t+1} = l_t$
* La ecuación de __predicción extra-muestral__ es $\hat{y}_{T+h} = \hat{y}_{T+1} = l_T$

Dos estimaciones razonables de $l_t$, el nivel de la serie en el periodo $t$, son el valor observado para la serie en ese periodo $y_t$ y el nivel del periodo previo $l_{t-1}$. La estimación final de $l_t$ es una media ponderada de ambas y esta estimación final es la previsión de la serie para el periodo siguiente. 

### Estimación de los parámetros del modelo {-}
    
Dado el proceso iterativo para el cálculo de $l_t$ se necesita un __valor inicial__ de arranque $l_0$. Cada programa estadístico usa su propio método para obtener $l_0$.
    
Respecto de $\alpha$, usualmente se estima el valor __optimo__ según un criterio de precisión de la predicción. El parámetro $\alpha$ __se puede interpretar__ como:

* Si $\alpha = 1$ se tiene el _método ingenuo I_ ($\hat{y}_{t+1}=y_t$), óptimo cuando el nivel de la serie varía constantemente en el tiempo.
* Si $\alpha = 0$ se tiene $\hat{y}_{t} =l_0$, óptimo cuando el nivel permanece constante en el tiempo.

### Ejemplo {-}

Vamos a usar el método de alisado exponencial simple para predecir la serie Libros. Usaremos para ello la función `ses` (_simple exponential smoothing_) con una previsión a 5 años vista (`h = 5`). Esta función estima los valores de $l_0$ y $\alpha$ que maximizan la función de verosimilitud, pero se pueden elegir otros criterios con el parámetro `opt.crit`.

```{r}
librosf <- ses(libros, h = 5, level = 95)
summary(librosf)
```

Veamos la salida en detalle:

* El valor de $\alpha$ que optimiza el criterio usado para medir la calidad del ajuste es $\alpha =$ `r round(librosf$model$par[1],2)`, un valor muy cercano a 1. Esto es un indicativo de que: i) la serie Libros cambia de nivel de forma constante, un rasgo en los procesos puramente estocásticos como el paseo aleatorio; ii) y el método de alisado exponencial simple se aproxima al método Ingenuo I. 
* El valor de arranque $l_0$ óptimo es `r round(librosf$model$par[2],2)`. 
* _sigma_ es la desviación típica del error (aditivo) de predicción. Se diferencia de RMSE en el denominador. Para calcular sigma en lugar de dividir por $T$ se divide por $T$ menos el número de parámetros estimados (en este caso 3, $l_0$, $\alpha$ y _sigma_).
* La calidad de ajuste es razonable, como evidencia el error porcentual medio del 7%.
* Las predicciones son las mismas para los 5 años, como cabe esperar (recuerda que $\hat{y}_{T+h} = \hat{y}_{T+1}$).

```{r}
tail(librosf$model$states, n = 4)
```

En el objeto `librosf` la matriz `librosf$model$states` guarda todos los valores del nivel obtenidos con la ecuación recursiva, incluidos el valor de arranque, así que es una matriz con $T+1$ filas. Puedes ver el valor de $l_{2018}$ en su última fila, que vale `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Así, la predicción para $2019$ es $\widehat{y}_{2019}=l_{2018}=$ `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Igualmente $\widehat{y}_{2020}=l_{2018}=$ `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Es decir, todas las previsiones son iguales a $l_{2018}$.

La figura 6 muestra la serie Libros y las previsiones extra-muestrales, que son constantes, y el intervalo de confianza. Conforme aumentamos el horizonte de predicción, el intervalo de confianza es más amplio como reflejo de la mayor incertidumbre en la predicción.
 
```{r}
autoplot(librosf,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 6. Libros y predicción con alisado simple")
```

\

## Alisado exponencial de Holt (A, N)

El alisado exponencial de Holt es adecuado para una serie no estacionaria y sin estacionalidad.

### Formulas interactivas de sus componentes {-}

Las __ecuaciones recursivas__ son
$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} 
\end{aligned}
$$
La ecuación de la __predicción intra-muestral__ a un periodo vista es
$$\hat{y}_{t+1} = l_t + b_t,$$
\noindent de forma que la ecuación de __predicción extra-muestral__ es 
$$\hat{y}_{T+h}=l_T + h b_T.$$ 
 
Dos estimaciones razonables del nivel de la serie en el periodo $t$ son el valor observado para la serie en ese periodo $y_t$, y una estimación del nivel del periodo $t$ realizada desde el periodo $t-1$: $l_{t-1} + b_{t-1}$. Por otro lado, dos estimaciones razonables de la pendiente de la serie en el periodo $t$ son el último cambio de nivel observado $l_t-l_{t-1}$, y el valor de la pendiente en el periodo previo, $b_{t-1}$. En ambos casos, nivel y pendiente, la estimación final es una media ponderada, parametrizada por $0 \leq \alpha, \: \beta \leq 1$.

### Estimación de los parámetros del modelo {-}

Para aplicar este método es necesario estimar unos valores iniciales $l_0$ y $b_0$ de las ecuaciones recursivas e identificar los valores más adecuados de los parámetros $\alpha$ y $\beta$. Los __valores óptimos__ de estos cuatro parámetros se obtienen optimizando una medida de precisión de las predicciones.

La interpretación del parámetro $\alpha$ es similar al caso del alisado exponencial simple.

__Interpretación del parámetro $\beta$__:

* Si $\beta = 1$, $b_t  = l_t - l_{t-1}$, la pendiente se actualiza constantemente porque varía periodo a periodo Puede ser un indicador de mal ajuste (tendencia no lineal o pendiente no aditiva).
* Si $\beta = 0$, $b_t = b_{t-1}= \ldots = b_0$, la pendiente se mantiene constante en el tiempo.

El _método ingenuo II_ es un caso concreto de Alisado de Holt. Si hacemos $\alpha=\beta = 1$, queda $l_t=y_t$ y $b_t=y_t-y_{t-1}$, por tanto
$$\hat{y}_{T+h}=l_T + h \cdot b_T = y_T + h(y_T - y_{T-1}).$$

### Ejemplo {-}

Vamos a usar el método de alisado de Holt para predecir de nuevo la serie Libros. Usaremos para ello la función `holt` con una previsión a 5 años vista (`h = 5`).

```{r}
librosf <- holt(libros, h = 5, level = 95)
summary(librosf)
```

Los valores óptimos de los cuatro parámetros son $\alpha=$ `r round(librosf$model$par[1],2)`, $\beta=$ `r round(librosf$model$par[2],2)`, $l_0 =$ `r round(librosf$model$par[3],2)` y $b_0 =$ `r round(librosf$model$par[4],2)`. Observa que $\alpha$ es prácticamente 1 y que $\beta$ es cero. Si aplicamos estos valores de los parámetros a las ecuaciones recursivas y la predicción extra-muestral, obtenemos $y_{T+h}=y_T + hb_0$: la predicción es el último valor observado más la primera pendiente estimada.

La calidad de las predicciones es razonable, con un error porcentual medio del 6.7%, y se ha mejorado respecto del alisado exponencial simple.

```{r}
tail(librosf$model$states, n = 4)
```

De nuevo, en el objeto `librosf` la matriz `librosf$model$states` guarda todos los valores obtenidos con las ecuaciones recursivas, en este caso el nivel y la pendiente, incluidos los valores de arranque. Puedes ver los valores de $l_{2018}$ y $b_{2018}$ en su última fila, que valen respectivamente `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Así, la predicción para $2019$ es $\widehat{y}_{2019}=l_{2018} + b_{2018}=$ `r formatC(librosf$model$states[27, 1], format = "f", digits = 2)` $+$ `r formatC(librosf$model$states[27, 2], format = "f", digits = 2)` $=$ `r formatC(sum(librosf$model$states[27,]), format = "f", digits = 2)`. Igualmente $\widehat{y}_{2020}=l_{2018} + 2\cdot b_{2018}=$ `r formatC(librosf$model$states[27,1] + 2* librosf$model$states[27,2], format = "f", digits = 2)`. Es decir, el incremento entre previsiones es contante e igual a $b_{2018}$ que, por ser $\beta$ prácticamente nulo, coincide con $b_0$.

La figura 7 muestra la serie Libros y las previsiones extra-muestrales que muestran una ligera tendencia creciente.
 
```{r}
autoplot(librosf,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 7. Libros y predicción con alisado de Holt")
```

\

## Alisado exponencial con pendiente amortiguada (Ad, N)

Las previsiones con el método de Holt presentan siempre una pendiente constante. En previsiones a corto plazo esto no es un problema, pero para previsiones a largo plazo la experiencia indica que suele aparecer un sesgo de previsión. El alisado exponencial con pendiente amortiguada trata de corregir esta limitación. El mecanismo, propuesto por Gardner y McKenzie en 1985, es introducir un nuevo parámetro $0 \leq \phi \leq 1$ que _amortigua_ la tendencia hasta hacerla plana en el largo plazo.


### Formulas interactivas de sus componentes {-}

Las __ecuaciones recursivas__ son
$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+\phi b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)\phi b_{t-1} 
\end{aligned}
$$
La ecuación de la __predicción intra-muestral__ a un periodo vista es
$$\hat{y}_{t+1} = l_t + \phi b_t,$$
\noindent de forma que la ecuación de __predicción extra-muestral__ es 
$$\hat{y}_{T+h}=l_T + (\phi + \phi^2 + \ldots + \phi^h) b_T.$$ 
 
Si $\phi = 1$ se tiene el alisado de Holt y si $\phi = 0$ se tiene el alisado simple. Para valores entre $0$ y $1$ en el corto plazo las predicciones tienen pendiente y en el largo plazo se hacen constantes e iguales a $l_T + \phi b_T/(1 - \phi)$.

### Ejemplo {-}

Vamos a usar el método de alisado con amortiguamiento para predecir, una vez más, la serie Libros añadiendo a la función `holt` el argumento `damped = TRUE`. Por razones prácticas el rango de búsqueda de $\phi$ queda en el intervalo $[0.8, 0.98]$. En este caso, para ver el efecto del _amortiguamiento_ vamos a fijar el valor de $\phi$ a $0.9$ y vamos a pedir un horizonte temporal más largo.

```{r}
librosfd <- holt(libros, damped = TRUE, h = 15, phi = 0.9)
summary(librosfd)
```

La figura 8 muestra la serie Libros, su estimación (intra-muestral) y las predicciones a 15 años vista. Observa que la pendiente de las previsiones se _amortigua_ en el tiempo, de forma que al principio las previsiones crecen más rápidamente que en los últimos años.
 
```{r}
autoplot(librosfd,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 8. Libros y predicción con alisado exponencial con amortiguamiento",
         PI = FALSE)
```

\

## Alisado de Holt-Winters aditivo (A, A) y multiplicativo (A, M)

El método de alisado exponencial de Holt-Winters es adecuado para una serie con tendencia y con estacionalidad. Existen dos versiones según que el esquema sea aditivo o multiplicativo.

### Alisado de Holt-Winters aditivo (A, A) {-}

Las __ecuaciones recursivas__ de actualización son:
$$
\begin{aligned}
l_t & =\alpha (y_t - s_{t-m} ) + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma (y_t - l_{t-1} - b_{t-1}) + (1 - \gamma)s_{t-m}
\end{aligned}
$$
con $0 \leq \alpha, \beta, \gamma \leq 1$.

La ecuación de la __predicción intra-muestral__ a un periodo vista es 
$$\hat{y}_{t+1}  = l_t + b_t + s_{t+1-m},$$
\noindent de forma que la ecuación de __predicción extra-muestral es__:
$$\hat{y}_{T+h}=l_T + h b_T + s_{T+h - m(k+1)},$$ 
\noindent con $k = \lfloor(h-1)/m\rfloor$.

### Alisado de Holt-Winters multiplicativo (A, M) {-}

Las __ecuaciones recursivas__ de actualización son:
$$
\begin{aligned}
l_t & =\alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma \frac{y_t}{l_{t-1} + b_{t-1}} + (1 - \gamma)s_{t-m}
\end{aligned}
$$

La ecuación de la __predicción intra-muestral__ a un periodo vista es 
$$\hat{y}_{t+1}  = (l_t + b_t)s_{t+1-m},$$
de forma que la ecuación de __predicción extra-muestral es__:
$$\hat{y}_{T+h}=(l_T + h b_T)s_{T+h - m(k+1)}.$$ 

### Ejemplo {-}

Vamos a usar el método de Holt-Winters para predecir la serie Nacimientos, que presentaba un esquema multiplicativo. Para ello usaremos la función `hw` con el argumento `seasonal = "multiplicative"` (que sería `seasonal = "additive"` en caso de esquema aditivo). Vamos a considerar la serie Nacimientos desde enero de 2000 y pedir una previsión a dos años vista.

```{r}
nacimientosb <- window(nacimientos, start = 2000)
nacimientosbf <- hw(nacimientosb, seasonal = "mult", h = 24)
summary(nacimientosbf)
```

Los valores óptimos de los parámetros son $\alpha=$ `r round(nacimientosbf$model$par[1],2)`, $\beta=$ `r round(nacimientosbf$model$par[2],2)` y $\gamma=$ `r round(nacimientosbf$model$par[3],2)`. Los valores tan bajos para $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, modifican su valor muy lentamente. Es decir, hay pendiente y hay efecto estacional, pero permanecen constantes en el tiempo.

La calidad de las predicciones es notable, con un error porcentual medio del 1.8%. Recuerda que con el método ingenuo con estacionalidad el error era del 3.6%.

Los últimos valores de las componentes son 
```{r, eval = FALSE}
TT <- nrow(nacimientosbf$model$states)
nacimientosbf$model$states[TT,]
```

```{r, echo = FALSE}
TT <- nrow(nacimientosbf$model$states)
round(nacimientosbf$model$states[TT,], 3)
```

Como el último dato de la serie es diciembre de 2018, los valores del nivel $l$ y la pendiente $b$ mostrados corresponden a ese periodo. Sin embargo, la componente estacional tiene un orden muy peculiar: s1 es el valor estacional para diciembre (mes del último dato), s2 el de noviembre, s3 de octubre, hasta s11 que sería febrero y s12 que es enero. Podemos reproducir las predicciones para los primeros 12 meses de enero a diciembre con (ojo, el etiquetado de la salida no es correcto):

```{r}
(nacimientosbf$model$states[TT, 1] + (1:12)*nacimientosbf$model$states[TT, 2]) * 
  nacimientosbf$model$states[TT, 14:3]
```

La figura 9 muestra la serie Nacimientos y las previsiones extra-muestrales.
 
```{r}
autoplot(nacimientosbf,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 9. Nacimientos y predicción con alisado de Holt-Winters multiplicativo",
         PI = FALSE)
```

## Ejemplo con transformación logarítmica

Una alternativa a predecir la serie Nacimientos, que tiene esquema multiplicativo, es predecir la transformación logarítmica de la serie, que tendrá un esquema aditivo. Después, se aplica la transformación inversa y se obtienen las predicciones de la serie original.

Este proceso se puede realizar de forma sencilla y transparente con cualquiera de las funciones de alisado exponencial que hemos visto a partir de los argumentos `lambda` y `biasadj`.

* `lambda = 0` indica a la función de alisado que se ha de realizar la transformación logarítmica de la serie. Es un parámetro de la transformación Box-Cox que veremos en detalle en el tema 3. 
* `biasadj = TRUE` es necesario si tras una transformación de la serie original queremos que las predicciones sean insesgadas. Sea $y_t$ la serie original y $z_t=log(y_t)$ su transformación logarítmica. Si obtenemos una predicción $\hat{y}_t$ de la serie original, esta será insesgada $E[\hat{y}_t]=y_t$. Ahora bien, si obtenemos una predicción $\hat{z}_t$ de la serie transformada, podemos pensar que $e^{\hat{z}_t}$ es una predicción insesgada de la serie original, pero resulta que $E[e^{\hat{z}_t}] \neq y_t$. Es decir, la exponencial de la predicción de la serie transformada logarítmicamente no es insesgada. Si el argumento `biasadj` es fijado a FALSE, las predicciones se calcularan de forma directa deshaciendo la transformación y serán sesgadas; si es fijado a TRUE, las predicciones se calcularan por medio de una fórmula alternativa y serán insesgadas. En ambos casos las estimaciones son consistentes, así que para series largas no debería observarse mucha diferencia entre las dos alternativas.

Vamos a practicar el uso de estos argumentos con la serie Nacimientos. Como se va a predecir el logaritmo de la serie, se debe indicar a la función `hw` que use el modelo Holt-Winters aditivo.

```{r}
nacimientosbfl <- hw(nacimientosb, 
                     seasonal = "addit", 
                     h = 24, 
                     lambda = 0, 
                     biasadj = TRUE)
summary(nacimientosbfl)
```

Observa que en este caso la calidad de las predicciones (MAPE = 1.9%) es inferior a la obtenida con la serie sin transformar.

La figura 10 muestra la serie Nacimientos y las previsiones extra-muestrales obtenidas con y sin la transformación logarítmica.
 
```{r, echo = FALSE}
autoplot(nacimientosb,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 10. Nacimientos y dos predicciones con alisado de Holt-Winters") + 
  autolayer(nacimientosbf, series = "Nacimientos", PI = FALSE) + 
  autolayer(nacimientosbfl, series = "Nacimientos (log)", PI = FALSE) + 
  guides(colour = guide_legend(title = "Predicción")) + 
  theme(legend.position=c(0.98,0.98), legend.justification=c(1,1)) 
```

La siguiente tabla muestra las predicciones de Nacimientos obtenidas sin transformar la serie, con transformación logarítmica y predicciones insesgadas (`biasadj = TRUE`), y con transformación logarítmica y predicciones sesgadas (`biasadj = FALSE`).

```{r, echo = FALSE}
nacimientosbfl2 <- hw(nacimientosb, seasonal = "addit", h=24, lambda = 0, biasadj = FALSE)
datos <- cbind(
  `Sin transformar` = nacimientosbf$mean,
  `log(Nac) insesgadas` = nacimientosbfl$mean,
  `log(Nac) sesgadas` = nacimientosbfl2$mean
  )
head(datos, 12)
```

Observa que las predicciones sesgadas son menores que las insesgadas. Esto siempre es así. La diferencia depende fundamentalmente de la varianza del error, _sigma_ al cuadrado en la salida de los métodos de alisado exponencial. Cuanto mayor es la varianza del error, mayores son las diferencias.

Por otro lado, las predicciones obtenidas sin y con la transformación logarítmica no guardan ninguna relación.

**Ni la transformación logarítmica ni el uso de predicciones insesgadas aseguran mejores predicciones respecto de otras opciones**, como pueden ser trabajar con predicciones sesgadas o no realizar la transformación logarítmica.

\

## Casos generales de alisado exponencial

En los epígrafes previos hemos visto cinco de los casos expuestos en la taxonomía del epígrafe 4.3, y las funciones de `R` asociadas. Veamos ahora como estimar cualquiera de los quince modelos que surgen según las diferentes posibilidades de la tendencia (N, A, Ad, M y Md) y de la estacionalidad (N, A y M). 

Recordemos que al añadir el error, aditivo o multiplicativo, estos quince modelos se convierten en treinta. Sin embargo, el tipo de error no influye en el cálculo de las previsiones, solo influye en el cálculo del intervalo de confianza de estas.

### La función `ets` {-}

Podemos estimar cualquiera de los treinta modelos usando la función `ets` del paquete `forecast`. A diferencia de las funciones previas `ses`, `holt` y `hw`, la función `ets` solo estima los modelos, pero no produce predicciones. Para ello habrá que usar la función `forecast` sobre un modelo estimado con `ets`. Mira la ayuda para ver una explicación detallada de los argumentos de estas funciones.

* El tipo de modelo en `ets` se especifica con el argumento `model`, un código de tres letras indicando el tipo de Error, Tendencia y eStacionalidad (ETS). Por ejemplo, `model = "ANN"` indica un modelo con error aditivo, sin tendencia ni estacionalidad, es decir, el alisado exponencial simple; `model = "AAN"` indica un modelo con error aditivo, pendiente aditiva, pero sin estacionalidad, el alisado exponencial de Holt. El alisado exponencial de Holt-Winters multiplicativo sería `model = "AAM"`.
* Si se desea incluir amortiguamiento, hay que incluir el argumento `damped = TRUE`. 
* Por defecto `ets` no considera modelos con tendencia multiplicativa (últimas dos líneas de la taxonomía del epígrafe 5.3). Debes fijar el parámetro `allow.multiplicative.trend=TRUE` para contemplar esta opción.
* Además, se sigue disponiendo de los argumentos `lambda` y `biasadj`.

__Criterios de optimización__

Fijado un modelo, `ets` estima por defecto sus parámetros maximizando la función de verosimilitud. Esta búsqueda esta restringida a $0 < \beta < \alpha < 1$, $0 < \gamma < 1 - \alpha$ y $0.8 < \phi < 0.98$. Es decir, los tres primeros parámetros nunca pueden ser 0 o 1, y en la práctica sus valores límite son 0.0001 y 0.9999.

Puedes cambiar el criterio de optimización con el argumento `opt.crit`. Por defecto vale "lik", pero si lo fijas a `opt.crit = "mse"` se estiman los parámetros que minimizan el error cuadrático medio. Otra opción interesante es `opt.crit = "amse"` que minimiza la media de los errores cuadráticos medios obtenido sobre las previsiones a `nmse` periodos vista. En este caso usa el argumento `nmse` para fijar el valor numérico del horizonte temporal.

__Selección de modelos__

Lo más habitual es no saber cual es el mejor modelo, entendiendo como tal, el que mejor se ajusta a la serie temporal. De hecho, si lo que buscamos es predecir bien, más que entender la naturaleza del proceso generador de datos, el mejor modelo será el que mejor prediga.

Si en una de las tres letras del código del modelo se indica "Z", la función `ets` selecciona de entre los modelos posibles el que mejor se ajusta. Por ejemplo, `model = "AAZ"` indica un modelo con error y pendiente aditivos y dejaría a `ets` la búsqueda de la mejor opción para la estacionalidad (nula, aditiva o multiplicativa). Si se especifica `model = "ZZZ` junto con `damped = NULL` (opciones por defecto) se dejaría a la función total libertad para buscar entre todos los modelos (excepto aquellos con pendiente multiplicativa). Si se desea restringir la búsqueda a modelos sin amortiguamiento basta indicar `damped = FALSE` y si se desea restringir la búsqueda solo a modelos aditivos se puede usar el argumento `additive.only = TRUE`.

Queda pendiente saber que criterio se usa para seleccionar el modelo cuando se ofrece esta opción. Esto se hace a partir de un criterio de información entre Akaike (aic), Akaike corregido para pequeñas muestras (aicc) y el Bayesiano (bic). Sus fórmulas son:
$$aic = -2log(L) + 2k$$
$$aicc = aic + \frac{k(k+1)}{T-k-1}$$
$$bic=aic + k(log(T) - 2)$$
\noindent donde $L$ es la verosimilitud, $T$ el número de datos y $k$ el de parámetros (incluidos los puntos iniciales de arranque y la varianza residual).

Por defecto se usa Akaike corregido para pequeñas muestras, pero el argumento `ic` permite cambiar de criterio. 

### Una reflexión sobre los métodos automáticos de selección de modelos {-}

Con el comando `forecast(ets(nacimientos), h = 24)` obtenemos una predicción mensual a dos años vista del número de nacimientos en España. Así de simple, solo 31 caracteres. Todo esto gracias a que un algoritmo interno ha estimado los parámetros de múltiples modelos, elegido el mejor modelo de todos y lo ha usado para obtener las predicciones. Podemos afirmar que tenemos las mejores predicciones. Un momento, ¿podemos?

Parémonos a reflexionar sobre lo que hemos hecho --más bien lo que el algoritmo ha hecho-- y a contrastarlo con lo que nosotros queríamos. Por un lado, el algoritmo estima los parámetros de un menú fijo de modelos y para ello usa un criterio de optimización, que por defecto es maximizar la función de verosimilitud; cuando ya tiene estimados todos los modelos, elije el mejor usando el criterio de información de Akaike corregido para muestras pequeñas; y finalmente, nosotros medimos la capacidad predictiva del modelo seleccionado usando el error absoluto porcentual medio. Vaya, resulta que en los procesos de identificación y estimación del mejor modelo se usan dos criterios diferentes, que además no coinciden con nuestro criterio de calidad de las predicciones.

Si consideramos que la calidad de un modelo viene dada por el error absoluto porcentual medio en las predicciones intra-muestrales a un periodo vista (lo que hemos decidido llamar MAPE), ¿no deberíamos estimar los parámetros del modelo usando como criterio la minimización del MAPE?, ¿no deberíamos elegir entre varios modelos aquel que presenta un MAPE menor? De esta forma, en todos los pasos del proceso se usa el mismo criterio, que es, además, el criterio que hemos considerado adecuado para valorar la calidad de las predicciones.

Pero no es esto lo que hacemos. 

Nada nos garantiza que el modelo estimado y seleccionado por el algoritmo estime las mejores predicciones posibles. Y por _mejores_ quiero decir que de entre todos los posibles modelos del menú y todos los posibles valores de sus parámetros, el seleccionado sea que el minimiza nuestro criterio de calidad de las predicciones.

Ahora ya podemos dar respuesta a la pregunta del primer párrafo: no, no podemos afirmar que nuestras predicciones sean las mejores.

Alguien dirá que casi seguro entre las predicciones sub-óptimas obtenidas por el algoritmo con su extraña mezcla de criterios y las predicciones óptimas de verdad no habrá mucha diferencia. Total, que más da una función de verosimilitud que un criterio de información que una medida del error medio. Pero lo cierto es que no lo sabemos, no tenemos ni idea de la distancia que hay entre lo óptimo y lo sub-óptimo, y si el coste de equivocarme en las predicciones es alto, puede que incluso una pequeña diferencia sea relevante.

Esta reflexión realizada en el contexto de series temporales y para la función `ets` es aplicable a todos los casos donde dejamos que un algoritmo ya programado elija el mejor modelo, y se basa en el hecho de que rara vez los criterios de estimación y elección que usan los algoritmos coinciden con el concepto de calidad de ajuste que estamos interesados.

A pesar de lo aquí expuesto, como es más cómodo (y rápido) tirar de rutinas ya programadas que escribir tu propio código, seguiremos trabajando con modelos sub-óptimos y obteniendo estimaciones sub-óptimas, pero diciendo que son las mejores.

\

### Residuo aditivo versus residuo multiplicativo {-}

En los modelos de alisado estimados por la función `ets` la fórmula para el cálculo del residuo estimado depende de su naturaleza aditiva o multiplicativa.

Si el __residuo es aditivo__, entonces el modelo es $y_t = \hat{y}_t + \hat{\varepsilon}_t$ y el residuo se define de la forma usual 
$$\hat{\varepsilon}_t = y_t - \hat{y}_t.$$
Ahora bien, si el __residuo es multiplicativo__, entonces el modelo es $y_t = \hat{y}_t \cdot (1 + \hat{\varepsilon}_t)$, y no $y_t = \hat{y}_t \cdot \hat{\varepsilon}_t$, como se podría esperar. Por tanto, el residuo multiplicativo se define como 
$$\varepsilon_t = (y_t - \hat{y}_t)/\hat{y}_t.$$
De esta forma en ambos casos el residuo evoluciona alrededor del valor 0 y se le pueden imponer las hipótesis usuales de ruido blanco. 

La función `residual` permite extraer de un objeto `ets` el residuo del modelo. Si el modelo tiene residuo multiplicativo y se desea obtener el residuo aditivo, se debe usar con el argumento `type = "response"`.

\
\

# Ejemplo de aplicación: Libros

\

## Identificación y estimación del mejor modelo

Si estimamos el mejor modelo de alisado exponencial para la serie Libros sin ningún tipo de restricción, nos encontramos:

```{r}
librosEts <- ets(libros)
summary(librosEts) 
```

El modelo estimado es ETS(M,N,N) o "MNN", un modelo sin pendiente ni estacionalidad y con error multiplicativo. Es decir, $y_{t+1} = l_t \cdot (1 + \varepsilon_{t+1})$. 

El valor de $\alpha$ técnicamente es 1, indicando que el nivel de la serie varia en el tiempo y que realmente estamos usando para las previsiones el método ingenuo I.

Respecto de la calidad del modelo, el valor de MAPE= $`r round(accuracy(librosEts)[5],1)`$% evidencia que estamos ante un modelo que ajusta razonablemente bien a los datos, y MASE= $`r round(accuracy(librosEts)[6],2)`$ indica que el modelo de alisado exponencial simple reduce en solo un $`r 100 - round(100*accuracy(librosEts)[6],0)`$% el error del método ingenuo I.


## Predicción

Mediante la función `forecast` podemos predecir los casos de Libros. Por tratarse de un modelo de alisado exponencial simple, la predicción es constante en el tiempo (véase figura 11).

```{r}
librosEtsPre <- forecast(librosEts, h = 5)
librosEtsPre
autoplot(librosEtsPre,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 11. Libros y predicción a 5 años vista")
```

## Análisis del error

El error de un modelo de alisado _contiene_ la componente de __Intervención__ y el propio término de __Error__. Ver numérica o gráficamente el error permite identificar fácilmente la presencia de valores atípicos (intervención).

El modelo de alisado tiene error multiplicativo así que debemos usar el argumento `type = "response"` para obtener el error aditivo con `residuals`.

```{r}
error <- residuals(librosEts, type = "response")
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "Figura 12: Error + Intervención") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(1993, 2019, 2)) 
```

La figura 12 muestra que aunque algún error supera las dos desviaciones típicas, ninguno puede ser considerado como claramente atípico.

## Validación: error extra-muestral

Vamos a mejorar la estimación de la calidad de las predicciones obteniendo el MAPE para __previsiones extra-muestrales a varios periodos vista__. Para ello vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie Libros. 

Recordemos que los resultados dependen tremendamente del punto de corte temporal seleccionado.


```{r}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos
librosIntraEts <- ets(librosIntra, model = "MNN")

# Predecimos los 7 años que hemos quitado de la serie y 
# vemos la calidad del ajuste.
librosExtraPre <- forecast(librosIntraEts, h = 6)
accuracy(librosExtraPre, librosExtra)
```

```{r, echo=FALSE}
error.muestral.1 <- round(accuracy(librosExtraPre, librosExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(librosExtraPre, librosExtra)[2,5],1)
```
Atendiendo al MAPE se tiene que el error de __previsión a un periodo vista__ en el __periodo intra-muestral__ de __1993 a 2012__ es del `r error.muestral.1`%; mientras que el error de __previsión a largo plazo__ en el __periodo extra-muestral__ de __2013 a 2018__ es del `r error.extramuestral.n`%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas. En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas. 

Un gráfico puede ayudar a entender este proceso de validación. En la figura 13:

* La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.
* La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.
* La previsión _intra_-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.
* La línea en rojo es la previsión _extra_-muestral a largo plazo: $\hat{y}_{T+h}=l_T$, donde $T=2012$. Observa que todas las previsiones están por encima del valor real de la serie.
* Al lado de cada previsión se ha indicado el error estimado (MAPE).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r,echo=FALSE}
autoplot(libros, series = "Libros",
         main="Figura 13. Libros, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Títulos"
         ) +
  autolayer(fitted(librosIntraEts), series = "Libros (ajustada)") + 
  autolayer(librosExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2012.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Libros"="black",
                               "Libros (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=1999, y=65000, label="7.2%", colour = "blue") +
  annotate("text", x=2016, y=72000, label="17.8%", colour = "red") +
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1)) 
```

\
\

__Nota:__ La presencia de tendencia, primero creciente y luego decreciente, en la serie Libros puede hacernos pensar que un modelo más adecuado para su ajuste y predicción sería ETS(M,A,N), forzando a que haya pendiente. De hecho, el error de estimación de este modelo es del 6.2%, frente al 7% para el modelo ETS(M,N,N). Sin embargo, el error de previsión extra-muestral a largo plazo para el modelo ETS(M,A,N) es del 31.5%, frente al 17.8% para el modelo ETS(M,N,N). De nuevo, incidir en que mayor calidad de ajuste no implica mayor calidad de predicción; y en que estos resultados dependen del punto de corte seleccionado.

# Ejemplo de aplicación: Nacimientos

Veamos un segundo ejemplo con la serie Nacimientos (desde el año 2000).

## Identificación y estimación del mejor modelo

Si damos total libertad al proceso de selección del mejor modelo, el óptimo tiene tendencia amortiguada con un parámetro $\phi = 0.98$, su máximo valor permitido. Este resultado aconseja repetir el proceso de selección del modelo restringido a aquellos sin amortiguamiento.

```{r}
nacimientosEts <- ets(nacimientosb, damped = FALSE)
summary(nacimientosEts) 
```

El modelo estimado es ETS(M,A,A), es decir, $y_{t+1} = (l_t + b_t +  s_{t+1-m}) \cdot (1+ \varepsilon_{t+1})$.

El bajo valor de $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, varían muy lentamente en el tiempo (véase la figura 14). 

```{r}
autoplot(nacimientosEts,
         xlab = "Periodo",
         main = "Figura 14. Componentes del modelo óptimo para Nacimientos")
```

Respecto de la calidad del modelo, el MAPE de `r round(accuracy(nacimientosEts)[5],1)`% indica que estamos ante un modelo que se ajusta muy bien a los datos; y el valor de MASE igual a `r round(accuracy(nacimientosEts)[6],2)` indica que este modelo reduce en un `r 100 - round(100*accuracy(nacimientosEts)[6],0)`% el error del método ingenuo con estacionalidad, el más sencillo posible, que ya utilizamos en el epígrafe 3 (aunque para la serie nacimientos completa).
      
Podemos ver los últimos valores estimados del nivel, la pendiente y la estacionalidad para interpretarlos.

```{r, eval = FALSE}
TT <- nrow(nacimientosEts$states)
nacimientosEts$states[TT,]
```

```{r, echo = FALSE}
TT <- nrow(nacimientosEts$states)
round(nacimientosEts$states[TT,],2)[1:7]
round(nacimientosEts$states[TT,],2)[8:14]
```

También podemos usarlos para predecir un año:
```{r, eval = FALSE}
nacimientosEts$states[TT, 1] + (1:12) * nacimientosEts$states[TT, 2] + 
  nacimientosEts$states[TT, 14:3]
```

```{r, echo = FALSE}
nacimientosEts$states[TT, 1] + (1:12) * nacimientosEts$states[TT, 2] + nacimientosEts$states[TT, 14:3]
```

Febrero es el mes con menor número de nacimientos: nacen `r abs(trunc(nacimientosEts$states[TT,13]))` bebés menos, respecto de la media anual. En octubre es cuando más niños nacen: `r trunc(nacimientosEts$states[TT,5])` más que la media anual.

Nuestra predicción para enero de 2019 es de `r as.integer((nacimientosEts$states[TT, 1] +  nacimientosEts$states[TT, 2]) + nacimientosEts$states[TT, 14])` bebés y para diciembre de 2019 de `r as.integer((nacimientosEts$states[TT, 1] + 12 * nacimientosEts$states[TT, 2]) + nacimientosEts$states[TT, 3])` bebés.

## Predicción

Si pedimos los valores de predicción tenemos (sólo se muestran los primeros meses):
```{r, eval = FALSE}
nacimientosEtsPre <- forecast(nacimientosEts, h = 24, level = 95)
nacimientosEtsPre
```

```{r, echo = FALSE}
nacimientosEtsPre <- forecast(nacimientosEts, h = 24, level = 95)
forecast(nacimientosEts, h = 5, level = 95)
```

Gráficamente,
```{r}
autoplot(nacimientosEtsPre,
         xlab = "",
         ylab = "Bebés",
         main = "Figura 15. Nacimientos y predicción")
```

## Análisis del error

El modelo de alisado tiene error multiplicativo así que debemos usar el argumento `type = "response"` para obtener el error aditivo con `residuals`.

```{r}
error <- residuals(nacimientosEts, type = "response")
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "Figura 16: Error + Intervención") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(2000, 2019, 2)) 
```

Se identifica un valor claramente atípico --supera las 4 desviaciones típicas-- que corresponde a enero de 2011. Abril de 2008 es otro candidato a intervención por alcanzar las 3 desviaciones típicas.

## Validación: error extra-muestral

En este caso vamos a aplicar la metodología __origen de predicción móvil__ (_rolling forecast origin_) o _rolling windows_. Asumimos que se precisan diez años para hacer una buena estimación, $k=120$, y que el horizonte temporal es de 12 meses, $h = 12$. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde uno a doce meses.
  
```{r}  
k <- 120                  
h <- 12                   
TT <- length(nacimientosb)
s <- TT - k - h           

mapeEts <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacimientosb, start = i + 1, end = i + k)
  test.set <-  subset(nacimientosb, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set,  model = "MAA", damped = FALSE)
  fcast <- forecast(fit, h = h)
  mapeEts[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

mapeEts <- colMeans(mapeEts)
round(mapeEts, 2)
```

El error extra-muestral a un periodo vista es comparable al error intra-muestral (1.9% frente a 1.8%). Aunque el error de previsión aumenta conforme lo hace el horizonte temporal, siempre se mantiene muy bajo. Por ejemplo, en las previsiones a 12 meses vista el error es del 3.5%.

\

## Otras alternativas para predecir Nacimientos

A la hora de predecir hay que ser un poco imaginativos, dedicarle tiempo y probar cosas. Por ejemplo, podríamos predecir los nacimientos a partir del ajuste de la transformación logarítmica. O podemos probar a cambiar el criterio de estimación de los parámetros o el de selección del modelo óptimo.

Yendo un poco más lejos, y dado que el número de nacimientos depende forzosamente del número de días del mes, podemos predecir los nacimientos medios por día (cociente entre los nacimientos de cada mes y el número de días del mes). Esta serie tendrá una componente estacional más suave, elimina el efecto de los meses de febrero bisiestos y tendrá, previsiblemente un mejor ajuste.

También podemos mezclar varios de los enfoques previos o ser aún más imaginativos.

El siguiente código muestra el MAPE (para previsiones intra-muestrales a un periodo vista) para varias de estas opciones. Puedes deducir que se está haciendo en cada caso a partir del código. Sería más adecuado usar otro criterio de validación diferente, pero el objetivo de este epígrafe es recalcar que no hay que quedarse con lo inmediato (predecir Nacimientos con las opciones por defecto de las funciones), sino probar y probar.

```{r}
# Serie Nacimientos
accuracy(ets(nacimientosb, 
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Transformación logarítmica
accuracy(ets(nacimientosb, 
             lambda = 0, 
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             lambda = 0, 
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Transformación logarítmica insesgada
accuracy(ets(nacimientosb, 
             lambda = 0, 
             biasadj = TRUE,
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             lambda = 0, 
             biasadj = TRUE,
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Nacimientos por dia
accuracy(ets(nacimientosb/monthdays(nacimientosb), 
             damped = FALSE))[5]
accuracy(ets(nacimientosb/monthdays(nacimientosb), 
             damped = FALSE, 
             opt.crit = "mse"))[5]
```

La principal conclusión en este caso es que salirse de la estimación directa sobre la serie original no reduce el error significativamente. Sin embargo, cabe destacar que, 

* El error de estimación de los nacimientos por día es menor, al tratarse de una serie con mejor comportamiento, aunque la ganancia no es mucha. (Véanse los dos últimos modelos respecto de los dos primeros)
* Usar la transformación logarítmica (con o sin predicciones insesgadas) no mejora la capacidad predictiva del modelo. (Véanse los modelos 3 a 6 respecto de los modelos 1 y 2)
* El mejor modelo estima los nacimientos por día y estima los parámetros minimizando el error cuadrático medio ("mse"). Todo menos lo _directo_.


\
\

# Resumen de los comandos utilizados


|Función  |Paquete | Descripción                                           |
|:--------------|:-----------|:-----------------------------------------------------|
|`meanf`        |forecast  |Predicción por media |
|`naive`        |forecast  |Predicción por método ingenuo I |
|`rwf`          |forecast  |Predicción con tendencia media |
|`snaive`	      |forecast  |Predicción por método ingenuo con estacionalidad |
|`accuracy`	    |forecast  |Calculo de la precisión del modelo |
|`forecast`     |forecast  |Predice valores extra-muestrales futuros de la serie |
|`ses`          |forecast  |Estimación del modelo de alisado exponencial simple|
|`holt`         |forecast   |Estimación del modelo de alisado exponencial de Holt|
|`hw`           |forecast |Estimación del modelo de alisado exponencial de Holt-Winters|
|`ets`          |forecast  |Estimación de una amplia familia de métodos de alisado exponencial|
|`residuals`    |stats   |Obtiene el residuo de un modelo estimado|
|`fitted`       |stats     |Obtiene las predicciones a un periodo vista intra-muestrales|

\
\

# Referencias

* Brown, R. G. (1959). _Statistical forecasting for inventory control_. Ed. McGraw/Hill.

* Gardner, Jr, E. S. y McKenzie, E. (1985) _Forecasting trends in time series_, Management Science, 31(10), pp. 1237–1246. doi:10.1287/mnsc.31.10.1237

* Holt, C. E. (1957). _Forecasting seasonals and trends by exponentially weighted averages_ O.N.R. Memorandum No. 52. Carnegie Institute of Technology, Pittsburgh USA. doi:10.1016/j.ijforecast.2003.09.015

* Hyndman, R. J. y Khandakar, Y. (2008) _Automatic Time Series Forecasting: The forecast Package for R_. Journal of Statistical Software, 27(3), pp. 1-22. doi:10.18637/jss.v027.i03

* Hyndman, R. J., Koehler, A., B., Ord, J. K. y Snyder, R. D. (2008) _Forecasting with Exponential Smoothing: the State Space Approach_. Ed. Springer.

* Makridakis, S. y  Hibon, M. (2000). _The M3-Competition: results, conclusions and implications_. International Journal of Forecasting, 16(4), pp. 451–476. doi:10.1016/S0169-2070(00)00057-1

* Winters, P. R. (1960). _Forecasting sales by exponentially weighted moving averages_. Management Science, 6, pp. 324–342.  doi:10.1287/mnsc.6.3.324

\
\
\
\
